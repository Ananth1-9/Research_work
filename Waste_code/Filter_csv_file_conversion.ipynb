{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8001ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the filter matching process...\n",
      "Loading primary file: /Users/ananthmugundhan/Documents/Research work/Space_data/hst_nsc.csv\n",
      "Loading HST MAST query results: /Users/ananthmugundhan/Documents/Research work/Space_data/HST_2025-09-17T14_58_13-07_00.csv\n",
      "Building filter lookup map from HST data...\n",
      "Filter map built. Found filter data for 174 unique coordinates.\n",
      "Matching coordinates and adding 'F814W' and 'F606W' columns to the output.\n",
      "Saving the updated data to 'hst_nsc_with_filters.csv'...\n",
      "\n",
      "Process complete!\n",
      "The new file 'hst_nsc_with_filters.csv' has been created with the added filter columns.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "# --- Configuration ---\n",
    "# Input file names\n",
    "NSC_FILE = '/Users/ananthmugundhan/Documents/Research work/Space_data/hst_nsc.csv'\n",
    "HST_MAST_FILE = '/Users/ananthmugundhan/Documents/Research work/Space_data/HST_2025-09-17T14_58_13-07_00.csv'\n",
    "\n",
    "# Output file name\n",
    "OUTPUT_FILE = 'hst_nsc_with_filters.csv'\n",
    "\n",
    "# Columns to use for matching and checking\n",
    "NSC_RA_COL = 'RA'\n",
    "NSC_DEC_COL = 'dec'\n",
    "HST_RA_COL = 'file_user_0_RA'\n",
    "HST_DEC_COL = 'file_user_1_dec'\n",
    "HST_FILTER_COL = 'sci_spec_1234'\n",
    "\n",
    "# Filters to check for\n",
    "FILTER_1 = 'F814W'\n",
    "FILTER_2 = 'F606W'\n",
    "\n",
    "# --- Main Script ---\n",
    "\n",
    "def process_files():\n",
    "    \"\"\"\n",
    "    Main function to load, process, and merge filter data.\n",
    "    \"\"\"\n",
    "    print(\"Starting the filter matching process...\")\n",
    "\n",
    "    # --- Step 1: Load the CSV files into pandas DataFrames ---\n",
    "    try:\n",
    "        print(f\"Loading primary file: {NSC_FILE}\")\n",
    "        df_nsc = pd.read_csv(NSC_FILE)\n",
    "        \n",
    "        print(f\"Loading HST MAST query results: {HST_MAST_FILE}\")\n",
    "        # Use low_memory=False to prevent potential dtype guessing errors on large files\n",
    "        df_hst = pd.read_csv(HST_MAST_FILE, low_memory=False)\n",
    "        \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: Could not find a required file: {e.filename}\", file=sys.stderr)\n",
    "        print(\"Please make sure both 'hst_nsc.csv' and 'HST_2025-09-17T14_58_13-07_00.csv' are in the same directory as the script.\", file=sys.stderr)\n",
    "        return\n",
    "\n",
    "    # --- Step 2: Create a lookup map from the HST data ---\n",
    "    # This map will store coordinates and the filters found for them.\n",
    "    # Key: (rounded_ra, rounded_dec), Value: set of filter names (e.g., {'F814W', 'F606W'})\n",
    "    print(\"Building filter lookup map from HST data...\")\n",
    "    filter_map = {}\n",
    "    \n",
    "    # We round coordinates to handle potential floating point inaccuracies\n",
    "    # 5 decimal places is usually sufficient for astronomical coordinate matching.\n",
    "    precision = 5\n",
    "\n",
    "    for index, row in df_hst.iterrows():\n",
    "        try:\n",
    "            # Get coordinate and filter info, ensuring filter data is a string\n",
    "            ra = float(row[HST_RA_COL])\n",
    "            dec = float(row[HST_DEC_COL])\n",
    "            filters_str = str(row[HST_FILTER_COL])\n",
    "\n",
    "            # Create a key with rounded coordinates\n",
    "            coord_key = (round(ra, precision), round(dec, precision))\n",
    "\n",
    "            # Initialize the set for this coordinate if it's the first time we see it\n",
    "            if coord_key not in filter_map:\n",
    "                filter_map[coord_key] = set()\n",
    "\n",
    "            # Check for the presence of our target filters and add them to the set\n",
    "            if FILTER_1 in filters_str:\n",
    "                filter_map[coord_key].add(FILTER_1)\n",
    "            if FILTER_2 in filters_str:\n",
    "                filter_map[coord_key].add(FILTER_2)\n",
    "\n",
    "        except (ValueError, TypeError):\n",
    "            # This handles cases where RA/Dec might be non-numeric in some rows\n",
    "            # print(f\"Skipping row {index+2} in {HST_MAST_FILE} due to invalid coordinate data.\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"Filter map built. Found filter data for {len(filter_map)} unique coordinates.\")\n",
    "\n",
    "    # --- Step 3: Use the map to add new columns to the nsc DataFrame ---\n",
    "    print(f\"Matching coordinates and adding '{FILTER_1}' and '{FILTER_2}' columns to the output.\")\n",
    "\n",
    "    # We define a function that can be applied to each row of the nsc dataframe\n",
    "    def check_filter_presence(row, filter_name):\n",
    "        try:\n",
    "            ra = float(row[NSC_RA_COL])\n",
    "            dec = float(row[NSC_DEC_COL])\n",
    "            coord_key = (round(ra, precision), round(dec, precision))\n",
    "\n",
    "            # Look up the coordinate in our map\n",
    "            found_filters = filter_map.get(coord_key, set())\n",
    "\n",
    "            # Return 'yes' if the filter is in the set, otherwise 'no'\n",
    "            return 'yes' if filter_name in found_filters else 'no'\n",
    "        except (ValueError, TypeError):\n",
    "            # Handle non-numeric RA/Dec in the source file\n",
    "            return 'no'\n",
    "\n",
    "    # Apply the function for each filter to create the new columns\n",
    "    df_nsc[FILTER_1] = df_nsc.apply(check_filter_presence, args=(FILTER_1,), axis=1)\n",
    "    df_nsc[FILTER_2] = df_nsc.apply(check_filter_presence, args=(FILTER_2,), axis=1)\n",
    "\n",
    "    # --- Step 4: Save the final result to a new CSV file ---\n",
    "    try:\n",
    "        print(f\"Saving the updated data to '{OUTPUT_FILE}'...\")\n",
    "        df_nsc.to_csv(OUTPUT_FILE, index=False)\n",
    "        print(\"\\nProcess complete!\")\n",
    "        print(f\"The new file '{OUTPUT_FILE}' has been created with the added filter columns.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: Could not save the output file. Reason: {e}\", file=sys.stderr)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    process_files()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a84b84a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3a135d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c33e91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Global)",
   "language": "python",
   "name": "global_py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
